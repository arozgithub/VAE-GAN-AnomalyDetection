# VAE-GAN-AnomalyDetection
A comparative study of GANs and VAEs for anomaly detection in image datasets (MNIST &amp; Fashion MNIST) with real-world extension using VAE on finance, healthcare, and cybersecurity data.

# ğŸ¯ Generative AI-Based Anomaly Detection in Images and Signals

This project implements and compares deep generative models â€” **GANs**, **Autoencoders**, and **VAEs** â€” for anomaly detection on image datasets (MNIST Digits & Fashion MNIST), with real-world extension using VAEs on a financially significant anomaly detection problem.

---

## ğŸ“Œ Objectives

- Build **Generative Adversarial Networks (GANs)** to generate and detect anomalies.
- Train **Autoencoders** & **Variational Autoencoders (VAEs)** to reconstruct and identify outliers.
- Compare generative models in terms of image quality, training stability, and latent space.
- Apply VAE to **real-world anomaly detection** for domains like finance, cybersecurity, and healthcare.

---

## ğŸ“‚ Datasets

| Dataset         | Description |
|----------------|-------------|
| **MNIST Digits** | 70,000 grayscale 28Ã—28 handwritten digit images |
| **Fashion MNIST** | Zalandoâ€™s 70,000 grayscale 28Ã—28 fashion item images |
| **Real-World Dataset** | Domain-specific dataset for anomaly detection (e.g., financial fraud, network intrusion, medical data) |

---

## ğŸ” Part 1: Exploratory Data Analysis (EDA)

- Load and preview the MNIST & Fashion MNIST datasets
- Show 5 random images per dataset
- Display number of samples, class labels, and class distributions

##ğŸ¤– Part 2: Generative Adversarial Networks (GANs)
##ğŸ—ï¸ Architecture:
Generator: Transforms random noise to image

Discriminator: Classifies real vs. generated images

Loss Functions:
d_loss = -torch.mean(torch.log(D(real)) + torch.log(1 - D(fake)))
g_loss = -torch.mean(torch.log(D(G(z))))


##ğŸ“ˆ Training:
Train on MNIST Digits

Train on Fashion MNIST (e.g., class "Shoe")

##ğŸ¨ Image Generation:
Generate 10 random digit images

Generate 5 images of digit "3" (roll number: L238023)

Generate fashion images of shoes

##ğŸ” Part 3: Variational Autoencoders (VAE)
##ğŸ§¬ Architecture:
Encoder â†’ Latent vector z (mu, logvar)

Reparameterization Trick

Decoder reconstructs from z

Loss = BCE + KL Divergence

python
Copy
Edit
kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
##âœ… Tasks:
Train VAE on MNIST Digits and Fashion MNIST (shoe)

Visualize latent space using t-SNE or PCA

Generate new digits, including 5 images of digit "2" (roll number: L238023)

ğŸ§ª Run:
bash
Copy
Edit
python vae/train_vae.py --dataset mnist --digit 2
python vae/train_vae.py --dataset fashion --class shoe

##ğŸ” Part 4: GAN vs. VAE Comparison
Aspect	GAN	VAE
Image Quality	High fidelity	Blurry but diverse
Training Stability	Sensitive to tuning	Stable
Latent Representation	Implicit, hard to interpret	Explicit and structured
Sampling Control	Random noise to image	Vector manipulation possible

##ğŸŒ Part 5: Real-World Anomaly Detection with VAE
âœ… Problem Chosen:
[e.g., Financial Fraud Detection]

Fraud costs banks $42B annually.

VAE detects suspicious transactions based on reconstruction loss.

##ğŸ§¬ Dataset:
Real-world dataset with labeled normal & anomalous instances


##ğŸ§  Model:
VAE trained on only normal data

Anomalies flagged by reconstruction error

##ğŸ“Š Evaluation:
Metrics: Precision, Recall, F1-Score

Plots: Reconstruction Error Histogram, ROC Curve

bash ##Clone the repo and install dependencies:
git clone https://github.com/yourusername/generative-anomaly-detection.git
cd generative-anomaly-detection
pip install -r requirements.txt
